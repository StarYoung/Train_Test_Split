#-*- coding:utf-8-*-
import codecs

import numpy as np
from sklearn.cross_validation import train_test_split
import re

pattern = re.compile('[a-z][a-z]+[1234]')


source = open('/home/hadoop/Desktop/72.txt')
dataTest = codecs.open('/home/hadoop/Desktop/data.txt','w','utf-8')
labelTest = open('/home/hadoop/Desktop/label.txt','w')
data=[]
label=[]
labelSet=set()

# build data[] and label[]
for line in source:
    line = line.decode('gbk')
    data.append(line)
    y = re.search(pattern,line)
    label.append(y.group(0))

for index1,l in enumerate(label):
    if l in labelSet:
        continue
    else:
        labelSet.add(l)
        newLabel=[l]
        newData = [data[index1]]

        # 找到所有同类的label，并新建data和label集合，并进行写入
        for index2,others in enumerate(label):
            if others == l:
                newData.append(data[index2])
                newLabel.append(others)
        X_train, X_test, Y_train, Y_test = train_test_split(newData, newLabel, test_size=0.1, random_state=47)
        for x_test in X_test:
            dataTest.write(x_test)
        dataTest.write('\n\n')
        for y_test in Y_test:
            labelTest.write(y_test+'\n')
        labelTest.write('\n\n\n')
